# HYBRID-DEEPFAKE-VIDEO-DETECTION-USING-XCEPTION-and-LSTM
Abstractâ€”Deepfakes, generated through Deep Generative Models like GANs, pose significant threats to digital authenticity, privacy, and public trust. In our approach, we integrate the spatial feature extraction capabilities of the Xception CNN with the temporal learning strengths of LSTM networks. We implemented a frame-based video classification pipeline, extracting uniformly sampled frames from real and manipulated videos. These frames underwent extensive data augmentation to improve generalization and prevent overfitting. Each frame was processed using a pre-trained Xception model for deep spatial feature extraction, and the extracted features were sequentially modeled using an LSTM layer to learn temporal dynamics across frames. Our model was trained on a carefully partitioned and augmented dataset, achieving high accuracy on unseen test samples and demonstrating strong generalization across datasets. Additionally, we integrated a real-time prediction module for direct classification of input videos as real or fake with confidence scores. This system contributes to ongoing efforts to counter the misuse of synthetic media by enabling scalable, automated, and real-time deepfake detection across diverse media sources.
